# Homework SP22 2nd No. 10 - Caroline Eggett


# Refer to chapter 4 (pages 147-177) of Mastering ’Metrics to answer the following questions.

# 1a In order to use a sharp regression discontinuity (RD) design, what must the
# relationship be between the running variable a and the treatment status Da?

# The treatment status will be soley determined by the function of the running
# variable.

# 1b How is a fuzzy RD design different from a sharp RD design?

# Sharp there is an additional window for randomization.  The status of the treatment will
# be determined by running variables, but treatment more intense near the cutoff point.

#2 Consider the following regression model
#   y = alpha + p*Da+ beta*a + epsilon
# where a is the running variable and Dais an indicator function of the form
# Da=
#   {1 if a ≥a0
#    0 if a < a0.

# Generate data from the model above using the following R code.

set.seed(1)
n = 1000
error = rnorm(n)
a = runif(n,0,2)
a0 = 1
Da = ifelse(a>a0,1,0)
y = 1 + 5*Da + 4*a + error

# 2a What is the true value of the treatment effect parameter (p) used to generate your
# data?

# The true value is 5 for the treatment effect parameter (p).

# 2b Plot y against the running variable a. How does the outcome variable change at
# the cutoff? Include your figure below.

plot(a, y)
abline(v=1)

# 2c Use the lm function in R to estimate the parameters (alpha, beta, p) from your data.
# What is the estimated treatment effect?

reg = lm(y~Da + a)
summary(reg)

# The estimated treatment effect is 3.98129.  This is close to the true value of 4.
# Same goes for what beta would be (5.10871).

# 2d Load the rdd package in R and estimate the same parameters using the RDestimate
# function command:

library(rdd)
summary(RDestimate(y ~ a , cutpoint = a0))

# Include the model output below.

# 2e What is the difference in the estimate of p in parts (c) and (d)?

# Both will cover the parameters, but in part c there is a smaller standard error than in part d.
# Basically the difference is how accurate it predicts the true parameter.

# 3 (Demand for Uber1) Understanding the demand for Uber is important not only for
# Uber’s own purposes of setting prices or designing its mobile app, but also for policy
# makers wanting to measure the consequences of ridesharing services on both consumers
# and competitors (e.g., taxis and public transit). Demand models usually take the form of 
# a regression of purchases on price. If prices are exogenously determined, then the coefficient 
# on price represents the causal effect or elasticity of price changes on demand. However, Uber’s 
# prices are not set randomly,but are instead set strategically and in “real-time” to reflect 
# local market conditions. Specifically, Uber’s prices are a function of a base fare, the user’s 
# time in the car, the distance traveled, and a surge price. If, for example, a ride is requested during a
# peak demand time (when the demand for rides exceeds the supply of drivers), Uber
# may charge a surge of 1.5 times the original fare to help move the market towards an
# equilibrium.

# While Uber’s prices are not set randomly, part of the price is random from the consumer’s perspective. 
# It turns out that Uber uses an algorithm to generate surge prices up to an arbitrary number of 
# decimal places, but then shows the consumer a surge price that is rounded to the nearest tenth 
# to ensure an easy user experience. For example, consider two consumers who are requesting a ride 
# in the same city, on the same day, at the same time, from around the same location. Since the 
# local market conditions are nearly identical, Uber’s algorithm would generate nearly identical surges (e.g., 1.2481
# and 1.2513). However, depending on where the generated numbers fall relative to the rounding cutoff, 
# the same two consumers could actually be shown two different surge prices (e.g., 1.2 and 1.3). 
# This allows for the use of regression discontinuity methods to estimate the causal effects of 
# price change on demand and any welfare measure thereafter.
    
# The uber data set reports individual-level session data from n = 1,000,000 users. A session is defined 
# as an instance when a user opens the Uber app, requests a fare, and then decides whether or not to 
# order the ride. The following variables are included: purchase is an indicator for whether a ride was 
# requested or not, generator is the surge price generated by Uber’s algorithm, surge is the surge price 
# actually seen by the consumer, post is an indicator for whether the generated price falls to the right of the
# rounding cutoff, and wait is the expected wait time in minutes.
    
# In reality, Uber’s surge prices can be 1.0,1.2,1.3,...,4.8,4.9,5.0, etc. Going forward,
# however, we will assume that the only surge price offered by Uber is 1.5 times the
# original fare. The set of generated prices then fall in the set (1,1.5), where 1.25 serves
# as the rounding cutoff.

# This question is based on the working paper “Using Big Data to Estimate Consumer Surplus: The Case
# of Uber” which is available at http://www.nber.org/papers/w22627. The data used in this question are
# simulated and roughly based on the results presented in the paper.

# After downloading the data from Carmen, set the path (e.g., "/Users/smith.6588/Downloads")
# and load the data into R using load("path/uber.RData").

load('uber.RData')

# 3a If one was to simply regress purchase on price, which assumption about regression
# models could be violated? How does a regression discontinuity approach help solve
# this problem?

# There is supposed to be a cutoff and by using regression discontinuity, we can
# have randomization near the cutoff.  These identical two groups can help eliminated
# the differences between the two groups. (we can do this be local markets nearly
# identical.)

# 3b Use the code below to plot purchase rates against the rounded generator values.
# How does the purchase rate change at the rounding cutoff of 1.25? Include your
# figure below.

gen.round = round(uber$generator,2)
gen.bins = sort(unique(gen.round))
rate.table = as.data.frame.matrix(table(gen.round,uber$purchase))
rates = as.numeric(rate.table[,2]/apply(rate.table,1,sum))
plot(gen.bins,rates,xlab="surge generator",ylab="purchase rate",pch=16,col=2)
abline(v=1.25)

# 3c Use the uber data to estimate the following demand model
# purchase = alpha + theta*post + beta1*wait + beta2*generator + epsilon
# where generator serves as the running variable. Report the model output below.

reg2 = lm(purchase~post + wait + generator, data=uber)
summary(reg2)

# 3d Interpret the estimate of theta.

# The estimate of theta is -0.0922331.  This means that there is a 9% drop as the price
# increases.  This suggests that the average purchase rate is 9% lower of 1.5 than it is
# at a surge of 1.

# 3e The analysis in part (c) uses all variation around the cutoff to estimate theta. Create
# a new variable called window that is defined as follows:

#     window =
#       {1 if |generator −1.25|< c
#        0 otherwise
# where c = 0.01. Estimate a second model that includes a window variable to restrict 
# the variation used to be that near the cutoff.
#   purchase = alpha + theta1*(post ∗window) + theta2*(post ∗(1 −window))+
#              y*window + β1wait + β2generator + epsilon

c = 0.01
window = ifelse(abs(uber$generator-1.25)<c, 1, 0)

# Perform a sensitivity analysis with respect to the choice of window. Do the point
# estimates and/or standard errors of theta1 change as window gets larger?

cbind(window, uber$generator)[1:10,]
cbind(window, uber$generator)[1:100,]
cbind(window, abs(uber$generator-1.25))

pw = uber$post*window
p1w = uber$post*(1-window)

reg3 = lm(uber$purchase~pw + p1w + window + uber$wait + uber$generator)
summary(reg3)

# first create a window size of 0.01 - 0.1
grid = (1:10)/100

# create storage space for theta estimates and its std error
theta = matrix(0, nrow=10, ncol=1)
setheta = matrix(0, nrow=10, ncol=1)
for(i in 1:10){
  window = ifelse(abs(uber$generator - 1.25)<grid[i],1,0)
  pw = uber$post * window
  p1w = uber$post*(1-window)
  reg = lm(uber$purchase~pw + p1w + window + uber$wait + uber$generator)
  theta[i] = reg$coefficients[2]
  setheta[i] = sqrt(diag(vcov(reg)))[2]
}

cbind(theta, setheta)

# lets visualize data
par(mfrow = c(1,2))
plot(grid, theta, xlab="window")
plot(grid, setheta, xlab="window", ylab="se(theta")


# 3h Based on your reading of the paper, discuss how the following issues would affect
# the authors’ estimated elasticities and subsequent estimates of consumer surplus.

# 3hi Ignoring local competition (e.g., taxis, Lyft, buses, trains).
# Because the authors view the consumer demand as inelastic (page 22),
# despite the existence of substitutes, there is a large consumer
# surplus.

# 3hii Using price variation during times of high demand to identify causal effects
# of price on demand.
# Again, due to the inelastic view of the authors (page 22), the consumer surplus
# for uber rides during high demand and price variation would still have a high
# consumer surplus (people are willing to pay a price even if it's higher).